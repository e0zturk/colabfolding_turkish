{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e0zturk/colabfolding_turkish/blob/main/folding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAAu6AXynIBF"
      },
      "source": [
        "#**Google Colab**\n",
        "## ColabFOLD & AlphaFold\n",
        "\n",
        "[Resmi Repo: LocalColabFold](https://github.com/YoshitakaMo/localcolabfold) | [YÃ¶ntem: AlphaFold2](https://nature.com/articles/s41586-021-03819-2)\n",
        "\n",
        "Bu Ã§alÄ±ÅŸma defteri, **LocalColabFold** mimarisini kullanarak amino asit dizilerinden (Fasta) yÃ¼ksek doÄŸrulukta **3 boyutlu protein yapÄ±larÄ± (.pdb)** ve kompleksleri oluÅŸturmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**LocalColabFold Nedir?**\n",
        "Google DeepMind tarafÄ±ndan geliÅŸtirilen **AlphaFold2** algoritmasÄ±nÄ±n, daha hÄ±zlÄ± ve eriÅŸilebilir bir versiyonudur. **MMseqs2** algoritmasÄ± kullanÄ±larak oluÅŸturulan derin Ã‡oklu Dizi HizalamasÄ± (MSA) ve PDB veritabanÄ±ndaki homolog ÅŸablonlarÄ±n (templates) entegrasyonuna dayanÄ±r. Bu yÃ¶ntem, pLDDT skorunu maksimize ederek deneysel verilere en yakÄ±n topolojiyi sunar.\n",
        "\n",
        "**Ã–zellikler:**\n",
        "* **Tahmin algoritmasÄ±**: **MMseqs2**\n",
        "\n",
        "* **HÄ±z:** Notebook editÃ¶rÃ¼, T4 GPU Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde, 3 cycle optimizasyon dÃ¶ngÃ¼sÃ¼nde (varsayÄ±lan); 100 amino asitlik ortalama bir sekansÄ±n tam analizini (MSA + 5 Model + Relaxation) yaklaÅŸÄ±k 10 dakika sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ yaptÄ±ÄŸÄ± deneme testlerinde doÄŸrulamÄ±ÅŸtÄ±r. HÄ±zÄ±nÄ±zÄ± arttÄ±rmak iÃ§in COLAB aboneliÄŸi & birim satÄ±n alma gerÃ§ekleÅŸtirebilirsiniz.\n",
        "\n",
        "* **Kompleks Modelleme:** VarsayÄ±lan olarak AlphaFold2_multimer_v3 motoru kullanÄ±lÄ±r. Bu sÃ¼rÃ¼m, protein-protein etkileÅŸim arayÃ¼zlerini (interface) Ã§Ã¶zmek iÃ§in Ã¶zel olarak eÄŸitilmiÅŸtir; dimer, trimer veya daha bÃ¼yÃ¼k oligomerik yapÄ±larÄ±n stokiyometrik analizini mÃ¼mkÃ¼n kÄ±lar."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â­•SÄ°STEM GEREKSÄ°NÄ°MLERÄ° :\n",
        "* 17+ GB DRÄ°VE DEPOLAMA ALANI\n",
        "\n",
        "---\n",
        "Colabfold programÄ±nÄ±n dosya paketleri yaklaÅŸÄ±k 16.3 GB yer kaplamaktadÄ±r. GiriÅŸ yapÄ±lan Google Drive hesabÄ±nÄ±zÄ±n yeterli depolama alanÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol ediniz. Aksi takdirde kurulum gerÃ§ekleÅŸmez."
      ],
      "metadata": {
        "id": "pOEyJvhFiFOS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PwW5AO7p6ZA"
      },
      "source": [
        "## **HazÄ±rlÄ±k ve Filtrasyon**\n",
        "\n",
        "\n",
        "Ã‡alÄ±ÅŸmanÄ±n saÄŸlÄ±klÄ± yÃ¼rÃ¼tÃ¼lmesi adÄ±na Google Colab sizden; **verilerinizi** tanÄ±mak, iÅŸlemek, Ã§alÄ±ÅŸtÄ±rmak ve sonuÃ§larÄ± kaydetmek amacÄ±yla `Google Drive` hesabÄ±na eriÅŸim izni isteyecektir. **LÃ¼tfen eriÅŸim izinlerini onaylayÄ±nÄ±z.**\n",
        "\n",
        "**Ä°lk defa Ã§alÄ±ÅŸtÄ±rmanÄ±z halinde Drive dizinine otomatik `Folding/data` dosyalarÄ± tanÄ±mlanacaktÄ±r. Ä°lk Ã§alÄ±ÅŸtÄ±rÄ±lmadan alÄ±nan HATA'yÄ± tekrar edilmemesi adÄ±na Ã§alÄ±ÅŸma dosyasÄ±nÄ± `raw_data` .fasta formatÄ±nda yÃ¼klemeniz gerekmektedir.**\n",
        "\n",
        "**`data/` klasÃ¶rÃ¼ne yÃ¼klediÄŸiniz `.fasta` dosyasÄ±nÄ±n tam adÄ±nÄ± hÃ¼crede girdi olarak verilmesi elzemdir.**\n",
        "\n",
        "**`raw_data = \"xxxx.fasta\"`**\n",
        "\n",
        "\n",
        "`raw_data` olarak atadÄ±ÄŸÄ±nÄ±z deÄŸiÅŸken dosyasÄ± iÃ§erisinde bulunan bazÄ± bozuk dosyalar ve tekrar eden diziler filtreleme aÅŸamasÄ±ndan geÃ§er.\n",
        "\n",
        "---\n",
        "### BÄ°LGÄ° â„¹ï¸\n",
        "- HÃ¼creyi Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra filtrelenmiÅŸ (`.fasta`) dosyasÄ±nÄ±n ne kadar saÄŸlam sekans iÃ§erdiÄŸi bilgisi Ã§Ä±ktÄ±da `SaÄŸlam sekans sayÄ±sÄ±:` ÅŸeklinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r. Bir sonraki bÃ¶lÃ¼mde kullanmak Ã¼zere not etmeyi **UNUTMAYINIZ**\n",
        "* HÃ¼cre, **`raw_data`** Ã¶nceden yÃ¼klenmiÅŸ filtresiz dosyasÄ±nÄ± (`xxx.fasta`) not defteri Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda `MyDrive/Folding` klasÃ¶rÃ¼nden silecektir. Onun yerine filtrelenmiÅŸ, saÄŸlam yapÄ±lar iÃ§eren aynÄ± isimde (`xxx.fasta`) dosyasÄ± Ã¼retecektir. Ä°ÅŸlenmemiÅŸ `.fasta` dosyanÄ±zÄ± local (kiÅŸisel bilgisayarÄ±nÄ±z) dosyalarda yedeklediÄŸinizden **emin** olun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6iXbdg_yqGFI",
        "outputId": "61955a37-4b98-44ed-9c91-5021a335080a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”Œ Google Drive baÄŸlanÄ±yor...\n",
            "Mounted at /content/drive\n",
            "\n",
            "âœ”ï¸ BaÄŸlanma baÅŸarÄ±lÄ±. Ä°ÅŸlenecek dosya doÄŸrulandÄ±: /content/drive/MyDrive/Folding/data/HPV.fasta\n",
            "\n",
            "ğŸ“Š Ä°statistikler:\n",
            "   - Ham Veri       : 121\n",
            "   - Tekrar Eden    : 0\n",
            "   - Bozuk (X > 3)  : 0\n",
            "   - Eliminasyon %  : %0.00\n",
            "\n",
            "âœ”ï¸ Filtreleme baÅŸarÄ±yla gerÃ§ekleÅŸti.\n",
            "SaÄŸlam sekans sayÄ±sÄ±: 121\n",
            "Ortalama Sekans UzunluÄŸu: 306.34\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "#___________Ã‡ALIÅMA ALANI__________\n",
        "raw_data = \"HPV.fasta\"  # Ã¶rnek dosya (kendiniz yÃ¼klemelisiniz, deÄŸiÅŸkene atamalÄ±sÄ±nÄ±z)\n",
        "Work_on_dir = \"/content/drive/MyDrive/Folding\"\n",
        "#__________________________________\n",
        "\n",
        "print(\"ğŸ”Œ Google Drive baÄŸlanÄ±yor...\")\n",
        "try:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(\"âŒ Drive baÄŸlantÄ±sÄ± kurulamadÄ±. LÃ¼tfen sol taraftaki 'Dosyalar' simgesinden Drive simgesine tÄ±klayarak manuel baÄŸlamayÄ± deneyin.\")\n",
        "    raise e\n",
        "\n",
        "data_dir = os.path.join(Work_on_dir, \"data\")\n",
        "folders_created = False\n",
        "\n",
        "if not os.path.exists(Work_on_dir):\n",
        "    os.makedirs(Work_on_dir, exist_ok=True)\n",
        "    folders_created = True\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "    folders_created = True\n",
        "\n",
        "if folders_created:\n",
        "    print(f\"â„¹ï¸ '{Work_on_dir}' ve 'data/' klasÃ¶rleriniz otomatik olarak oluÅŸturulmuÅŸtur.\")\n",
        "\n",
        "file_path = os.path.join(data_dir, raw_data)\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"\\nâš ï¸ LÃ¼tfen data klasÃ¶rÃ¼ne ({data_dir}) Ã§alÄ±ÅŸmak istediÄŸiniz '{raw_data}' dosyasÄ±nÄ± yÃ¼kleyiniz.\")\n",
        "else:\n",
        "    print(f\"\\nâœ”ï¸ BaÄŸlanma baÅŸarÄ±lÄ±. Ä°ÅŸlenecek dosya doÄŸrulandÄ±: {file_path}\\n\")\n",
        "\n",
        "    seen_sequences = set()\n",
        "    clean_sequences = []\n",
        "    removed_x_count = 0\n",
        "    removed_dup_count = 0\n",
        "\n",
        "    current_header = None\n",
        "    current_seq_lines = []\n",
        "\n",
        "    def process_sequence(header, seq_lines):\n",
        "        global removed_x_count, removed_dup_count\n",
        "        full_seq = \"\".join(seq_lines).strip().upper()\n",
        "        if not full_seq: return\n",
        "        if full_seq in seen_sequences:\n",
        "            removed_dup_count += 1\n",
        "            return\n",
        "        if full_seq.count(\"X\") > 3:\n",
        "            removed_x_count += 1\n",
        "            return\n",
        "        seen_sequences.add(full_seq)\n",
        "        clean_sequences.append((header, full_seq))\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line: continue\n",
        "            if line.startswith(\">\"):\n",
        "                if current_header:\n",
        "                    process_sequence(current_header, current_seq_lines)\n",
        "                current_header = line\n",
        "                current_seq_lines = []\n",
        "            else:\n",
        "                current_seq_lines.append(line)\n",
        "        if current_header:\n",
        "            process_sequence(current_header, current_seq_lines)\n",
        "\n",
        "    total_clean = len(clean_sequences)\n",
        "    if total_clean > 0:\n",
        "        with open(file_path, 'w') as f:\n",
        "            for header, seq in clean_sequences:\n",
        "                f.write(f\"{header}\\n{seq}\\n\")\n",
        "\n",
        "        total_raw = total_clean + removed_dup_count + removed_x_count\n",
        "        average = sum(len(seq) for _, seq in clean_sequences) / total_clean\n",
        "\n",
        "        print(f\"ğŸ“Š Ä°statistikler:\")\n",
        "        print(f\"   - Ham Veri       : {total_raw}\")\n",
        "        print(f\"   - Tekrar Eden    : {removed_dup_count}\")\n",
        "        print(f\"   - Bozuk (X > 3)  : {removed_x_count}\")\n",
        "        print(f\"   - Eliminasyon %  : %{((1-(total_clean/total_raw))*100):.2f}\")\n",
        "        print(f\"\\nâœ”ï¸ Filtreleme baÅŸarÄ±yla gerÃ§ekleÅŸti.\")\n",
        "        print(f\"SaÄŸlam sekans sayÄ±sÄ±: {total_clean}\")\n",
        "        print(f\"Ortalama Sekans UzunluÄŸu: {average:.2f}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ HATA: Filtreleme sonucu elde kalan veri yok.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jA4Mqky3x17"
      },
      "source": [
        "## **Veri iÅŸleme**\n",
        "**Ä°ÅŸlenmiÅŸ veriler Ã¼zerinde gerekli tÃ¼m ayarlamalarÄ±n gerÃ§ekleÅŸtiÄŸi kÄ±sÄ±mdÄ±r.**\n",
        "###**SÄ°STEM AYARLARI:**\n",
        "1. parÃ§alama stratejisi ayarlarÄ±\n",
        "-  mode : `aim` ya da `rate`\n",
        "- parÃ§a sayÄ±sÄ±: `split_param` (integer)\n",
        "2. RUN (Ã§alÄ±ÅŸtÄ±rma) ayarlarÄ±\n",
        "- Ã‡alÄ±ÅŸtÄ±rma modu : `monomer` ya da `multimerv3`\n",
        "- Ã‡alÄ±ÅŸtÄ±rÄ±lmak istenen parÃ§a sayÄ±sÄ± : `kota` (integer)\n",
        "- KaldÄ±ÄŸÄ±nÄ±z yerden devam etme: `take_up` = (boolen) , `resume_as` = (integer)\n",
        "- Sunucunun optimizasyon dÃ¶ngÃ¼sÃ¼: `cycle`(integer)\n",
        "\n",
        "---\n",
        "#####NOTLAR:\n",
        "* Ä°ÅŸlenmiÅŸ dosyanÄ±zÄ±n kaÃ§ tane sekans iÃ§erdiÄŸi bilgisini `HazÄ±rlÄ±k` bÃ¶lÃ¼mÃ¼ne giderek Ã¶ÄŸrenebilirsiniz.\n",
        "\n",
        "* Fasta formatÄ±ndaki dosyanÄ±zÄ±n sekans sayÄ±sÄ±nÄ±n uzun olmasÄ± programÄ±n tamamlanma sÃ¼resini uzatabilir. Bu sÃ¼reyi en aza indirmek iÃ§in `.fasta` dosyanÄ±z parÃ§alara ayÄ±rmanÄ±z Ã¶nemlidir.\n",
        "\n",
        "* ParÃ§alanmÄ±ÅŸ dosyalar _`Folding/*fasta_parts`_ dizinine kaydedilir.\n",
        "\n",
        "* Yeni bir iÅŸleme baÅŸlanÄ±ldÄ±ÄŸÄ±nda Ã¶nceki Ã§alÄ±ÅŸmalarda oluÅŸturulmuÅŸ _`*_fasta-parts`_ klasÃ¶rÃ¼ **silinmektedir**.\n",
        "\n",
        "---\n",
        "##### BÃ¶lme stratejisi\n",
        "* `rate` : ParÃ§alamak iÃ§in orantÄ±sal metod kullanÄ±r. Ortalama olarak istenilen `split_param` parÃ§a sayÄ±sÄ± kadar parÃ§aya bÃ¶lÃ¼nÃ¼r. Ã–rneÄŸin \"rate\", 5 olarak deÄŸiÅŸken atamasÄ± yapmak '**Toplam 5 parÃ§a olacak ÅŸekilde bÃ¶l**' anlamÄ±na gelir.\n",
        "\n",
        "* `aim`: ParÃ§alarÄ±n hedef sekans sayÄ±sÄ±na gÃ¶re dosyanÄ±zÄ± bÃ¶ler. `split_param` olarak yazdÄ±ÄŸÄ±nÄ±z uzunlukta eÅŸit parÃ§alar Ã¼retir. Son parÃ§a eÅŸit daÄŸÄ±lan sekans parÃ§alarÄ±ndan eksik kalabilir. Ã–rneÄŸin `\"aim\"` , `30` atamasÄ± yapmak '**ParÃ§alar 30 sekans iÃ§erecek ÅŸekilde bÃ¶l**' anlamÄ±na gelir.\n",
        "\n",
        "---\n",
        "##### RUN (Ã§alÄ±ÅŸtÄ±rma) stratejisi\n",
        "* Ã‡alÄ±ÅŸtÄ±rma modunu dimer, trimer yapÄ±larÄ± iÃ§in varsayÄ±lan `multimerv3` da tutmanÄ±zÄ± Ã¶neriyoruz.\n",
        "* `kota`: ParÃ§alanan `.fasta` dosyalarÄ±nÄ±  RUN (Ã§alÄ±ÅŸtÄ±rma) sunucusuna sÄ±rasÄ±yla dÃ¶ngÃ¼ halinde Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlar. Tavsiye edilen `1`'dir.\n",
        "* `take_up` kaldÄ±ÄŸÄ±nÄ±z yerden devam ettirmek iÃ§in `True` (aÃ§Ä±k) boolen deÄŸiÅŸkeni, varsayÄ±lan olarak kapatmak iÃ§in `False` boolen kullanabilirsiniz. `resume_as` hangi parÃ§adan devam etmek istediÄŸinizi belirtmek iÃ§indir. (Ã¶rn: `xxx_part3.fasta`) -> `resume_as = 3`\n",
        "* `cycle` deÄŸiÅŸkeni colabfold'un `.pdb` dosya taramasÄ±nda yaptÄ±ÄŸÄ± optimizasyon dÃ¶ngÃ¼ sayÄ±sÄ±dÄ±r. ProgramÄ±n hÄ±zÄ±nÄ± etkileyebilir. HÄ±z sÄ±ralamasÄ± : 1,3,5,6,10,12. Tavsiye edilen dengeli tarama '3' olarak ayarlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "\n",
        "---\n",
        "#####âš ï¸UYARI : Ã‡alÄ±ÅŸtÄ±rmadan Ã¶nce `--- KULLANICI AYARLARI ---` kÄ±smÄ±nÄ± kendi Ã§alÄ±ÅŸmanÄ±za gÃ¶re **revize** ediniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MLnhLGe-6V4q",
        "outputId": "15d30635-d05e-4a93-9191-0bd0ea8f6f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sistem HazÄ±r. Ä°ÅŸlenecek Dosya: HPV.fasta\n",
            "\n",
            "\n",
            "âš™ï¸Ayarlar: Mod=aim, Param=1, RunMod=monomerv2, Kota=1\n",
            "                Cycling=1,TakeUp=False, ResumeAs=6\n",
            "\n",
            "ğŸ§¹'*_fasta_parts' klasÃ¶rleri taranÄ±yor...\n",
            "\n",
            "Silme iÅŸlemi baÅŸarÄ±lÄ±. yeniden boÅŸ dizin oluÅŸturuluyor.\n",
            "\n",
            "â„¹ï¸ Mod: AIM -> Her dosyada en fazla 1 sekans olacak.\n",
            "\n",
            "\n",
            "âœ… Ä°ÅLEM TAMAM: Toplam 121 parÃ§a oluÅŸturuldu.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "# --- KULLANICI AYARLARI (SÄ°STEM AYARLARI) ---\n",
        "mode = \"aim\"  #rate\n",
        "split_param = 1\n",
        "run_mode = \"monomerv2\" #monomerv2\n",
        "kota = 1  # oluÅŸan parÃ§alarÄ± {kota} kere dÃ¶ngÃ¼yle Ã§alÄ±ÅŸtÄ±rÄ±r.\n",
        "take_up = False #False\n",
        "resume_as = 6  #part{i} ve sonrasÄ±\n",
        "cycle = 1 # hÄ±z sÄ±ralamasÄ±: 1,3,5,6,10,12\n",
        "# --------------------------------------------\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError\n",
        "    print(f\"Sistem HazÄ±r. Ä°ÅŸlenecek Dosya: {os.path.basename(file_path)}\\n\")\n",
        "    print(f\"\\nâš™ï¸Ayarlar: Mod={mode}, Param={split_param}, RunMod={run_mode}, Kota={kota}\\n\\\n",
        "                Cycling={cycle},TakeUp={take_up}, ResumeAs={resume_as}\\n\")\n",
        "except (NameError, FileNotFoundError):\n",
        "    print(\"âŒ HATA: 'HazÄ±rlÄ±k ve Filtrasyon' bÃ¶lÃ¼mÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸ veya dosya bulunamadÄ±.\")\n",
        "    print(\"LÃ¼tfen Ã¶nce HazÄ±rlÄ±k bÃ¶lÃ¼mÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
        "else:\n",
        "    # --- TEMÄ°ZLÄ°K ---\n",
        "    print(\"ğŸ§¹'*_fasta_parts' klasÃ¶rleri taranÄ±yor...\")\n",
        "    for item in os.listdir(Work_on_dir):\n",
        "        item_path = os.path.join(Work_on_dir, item)\n",
        "        if os.path.isdir(item_path) and item.endswith(\"_fasta_parts\"):\n",
        "            try:\n",
        "                shutil.rmtree(item_path)\n",
        "                print(f\"\\nSilme iÅŸlemi baÅŸarÄ±lÄ±. yeniden boÅŸ dizin oluÅŸturuluyor.\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Silinemedi: {item} -> {e}\")\n",
        "    # ----------------\n",
        "\n",
        "    abs_path = os.path.abspath(file_path)\n",
        "    base_name = os.path.splitext(os.path.basename(abs_path))[0]\n",
        "    output_dir = os.path.join(Work_on_dir, f\"{base_name}_fasta_parts\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # ------------------------\n",
        "\n",
        "    clean_sequences = []\n",
        "    current_header = None\n",
        "    current_seq_lines = []\n",
        "\n",
        "    with open(abs_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line: continue\n",
        "            if line.startswith(\">\"):\n",
        "                if current_header:\n",
        "                    full_seq = \"\".join(current_seq_lines).strip()\n",
        "                    if full_seq: clean_sequences.append((current_header, full_seq))\n",
        "                current_header = line\n",
        "                current_seq_lines = []\n",
        "            else:\n",
        "                current_seq_lines.append(line)\n",
        "        if current_header:\n",
        "            full_seq = \"\".join(current_seq_lines).strip()\n",
        "            if full_seq: clean_sequences.append((current_header, full_seq))\n",
        "\n",
        "    total_seqs = len(clean_sequences)\n",
        "    chunks = []\n",
        "\n",
        "    if total_seqs > 0:\n",
        "        if mode == \"rate\":\n",
        "            if split_param > 0:\n",
        "                chunk_size = math.ceil(total_seqs / split_param)\n",
        "                for i in range(0, total_seqs, chunk_size):\n",
        "                    chunks.append(clean_sequences[i:i + chunk_size])\n",
        "                print(f\"\\nâ„¹ï¸ Mod: RATE -> Toplam {total_seqs} sekans, ortalama {len(chunks)} dosyaya bÃ¶lÃ¼nÃ¼yor.\\n\")\n",
        "\n",
        "        elif mode == \"aim\":\n",
        "            if split_param > 0:\n",
        "                for i in range(0, total_seqs, split_param):\n",
        "                    chunks.append(clean_sequences[i:i + split_param])\n",
        "                print(f\"\\nâ„¹ï¸ Mod: AIM -> Her dosyada en fazla {split_param} sekans olacak.\\n\")\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            output_file = os.path.join(output_dir, f\"{base_name}_part{i + 1}.fasta\")\n",
        "            with open(output_file, 'w') as out_f:\n",
        "                for header, seq in chunk:\n",
        "                    out_f.write(f\"{header}\\n{seq}\\n\")\n",
        "\n",
        "        print(f\"\\nâœ… Ä°ÅLEM TAMAM: Toplam {len(chunks)} parÃ§a oluÅŸturuldu.\")\n",
        "\n",
        "    else:\n",
        "        print(\"âš ï¸ HATA: Dosya boÅŸ veya okunamadÄ±. LÃ¼tfen HazÄ±rlÄ±k bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFjSzilGjyMn"
      },
      "source": [
        "##**LOCAL COLAB FOLD KONTROLÃœ**\n",
        "`localcolabfold` dosyalarÄ±nÄ±n colab notebook'unun iÃ§inde varlÄ±ÄŸÄ±nÄ± sorgulamaktadÄ±r. EÄŸer yoksa `Drive` baÄŸlantÄ±sÄ± Ã¼zerinden `MyDrive` iÃ§inde `colabfold_yedek.tar` adÄ±nda editÃ¶rÃ¼n sunduÄŸu yedekleme dosyasÄ± kontrol edilir. Yedek kurulum sÄ±rasÄ±nda iÅŸlem yarÄ±da kesilir ise yukarÄ±daki menÃ¼den;\n",
        "`Ã‡alÄ±ÅŸma zamanÄ± > Ã‡alÄ±ÅŸma zamanÄ± ve baÄŸlantÄ±sÄ±nÄ± kes ve sil`\n",
        "yaptÄ±ktan sonra tekrar Drive baÄŸlanarak Ã§alÄ±ÅŸtÄ±rÄ±n.\n",
        "\n",
        "---\n",
        "######Not\n",
        "* `'LocalColabFold zaten yÃ¼klÃ¼'` ise lÃ¼tfen $PATH aÅŸamasÄ±na geÃ§iniz.\n",
        "* Aksi takdirde manuel kurulum baÅŸlatÄ±nÄ±z.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FEIZUgfMll0-",
        "outputId": "9741f8e6-8e22-4c05-8582-683c2e93e431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive kontrol ediliyor...\n",
            "\n",
            "ğŸ“¥ Drive yedeÄŸi bulundu: /content/drive/MyDrive/Folding/colabfold_yedek.tar\n",
            "\n",
            "â³ Yedek dosyasÄ± ÅŸimdi aÃ§Ä±lÄ±yor (HÄ±zÄ±nÄ±za gÃ¶re 5-10 dk sÃ¼rebilir)...\n",
            "âœ… Yedek .tar dosyasÄ± notebook'a yÃ¼klendi.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    Work_on_dir\n",
        "except NameError:\n",
        "    Work_on_dir = \"/content/drive/MyDrive/Folding\"\n",
        "\n",
        "install_path = \"/content/localcolabfold\"\n",
        "backup_path = os.path.join(Work_on_dir, \"colabfold_yedek.tar\")\n",
        "\n",
        "if os.path.exists(install_path):\n",
        "    print(\"âœ… DURUM: LocalColabFold zaten yÃ¼klÃ¼.\\n\")\n",
        "    print(\"Manuel kurulumu atlayÄ±p $PATH bÃ¶lÃ¼mÃ¼ne geÃ§ebilirsiniz.\")\n",
        "\n",
        "else:\n",
        "    print(\"Drive kontrol ediliyor...\\n\")\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    if os.path.exists(backup_path):\n",
        "        print(f\"ğŸ“¥ Drive yedeÄŸi bulundu: {backup_path}\\n\")\n",
        "        print(\"â³ Yedek dosyasÄ± ÅŸimdi aÃ§Ä±lÄ±yor (HÄ±zÄ±nÄ±za gÃ¶re 5-10 dk sÃ¼rebilir)...\")\n",
        "\n",
        "        !cp \"{backup_path}\" /content/\n",
        "        !tar -xf /content/colabfold_yedek.tar -C /content/\n",
        "        print(\"âœ… Yedek .tar dosyasÄ± notebook'a yÃ¼klendi.\")\n",
        "    else:\n",
        "        print(f\"âŒ '{backup_path}' yolunda yedek bulunamadÄ±.\")\n",
        "        print(\"LÃ¼tfen bir sonraki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rarak 'Manuel Kurulum' yapÄ±nÄ±z.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBVBuBwaurQs"
      },
      "source": [
        "## **Manuel Kurulum - ColabFold**\n",
        "\n",
        "Bu bÃ¶lÃ¼m, protein modelleme iÃ§in gerekli olan AlphaFold2 motorunu ve temel baÄŸÄ±mlÄ±lÄ±klarÄ± sisteme sunucudan kurar.\n",
        "\n",
        "---\n",
        "#####**Sistemin Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±:**\n",
        "**Girdi:**\n",
        "* Amino asit dizilerini iÃ§eren metin dosyalarÄ± (.fasta).\n",
        "\n",
        "**Ã‡Ä±ktÄ±lar:**\n",
        "* **_relaxed_...pdb:** Fiziksel enerji minimizasyonu (Amber) uygulanmÄ±ÅŸ, atomik Ã§akÄ±ÅŸmalarÄ±n giderildiÄŸi nihai ve en kararlÄ± model dosyasÄ±.\n",
        "* **_unrelaxed_...pdb:** AlgoritmanÄ±n Ã¼rettiÄŸi, henÃ¼z fiziksel optimizasyon yapÄ±lmamÄ±ÅŸ ham model dosyasÄ±.\n",
        "* **.json DosyalarÄ±:** Modellerin gÃ¼venilirlik skorlarÄ± ve sayÄ±sal metrik verileri.\n",
        "* **.png Grafikleri:** YapÄ±sal gÃ¼venilirlik (pLDDT) ve hizalama hatasÄ± (PAE) analiz gÃ¶rselleri\n",
        "\n",
        "---\n",
        "####âš ï¸UyarÄ±\n",
        "* localcolabfold dosyalarÄ± kurulumu iÃ§in lÃ¼tfen iÅŸlemin tamamen bitmesini bekleyiniz.\\\n",
        "Bu iÅŸlem 10-15 dakika sÃ¼rebilir\n",
        "* EÄŸer ilk defa not defterini Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, manuel kurulumundan sonra otomatize kurulum iÃ§in dosyalarÄ±n yedeÄŸi Ã§Ä±karÄ±lacaktÄ±r. (`colabfold_yedek.tar`)\\\n",
        "Bu iÅŸlem de 10-20 dakika daha zaman alabilir.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sg8Gs6RYuaXy",
        "outputId": "6261f471-60fb-4fed-bba9-5f14aed9eb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sistem zaten yÃ¼klÃ¼.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "install_path = \"/content/localcolabfold\"\n",
        "backup_path = os.path.join(Work_on_dir, \"colabfold_yedek.tar\")\n",
        "\n",
        "free_gb = shutil.disk_usage(\"/content\").free / (1024**3)\n",
        "if free_gb < 17:\n",
        "    raise SystemExit(f\"âŒ Disk alanÄ± yetersiz: {free_gb:.2f} GB\")\n",
        "\n",
        "force_reinstall = not os.path.exists(backup_path)\n",
        "\n",
        "if force_reinstall or not os.path.exists(install_path):\n",
        "    if os.path.exists(install_path):\n",
        "        !rm -rf {install_path}\n",
        "\n",
        "    print(\"ğŸŒ MANUEL KURULUM baÅŸlatÄ±lÄ±yor...\")\n",
        "    print(\"âš ï¸ YaklaÅŸÄ±k 17 GB indirme yapÄ±lacak. Bu iÅŸlem 10-15 dk sÃ¼rebilir...\\n\")\n",
        "    !curl -fsSL https://pixi.sh/install.sh | bash\n",
        "    !git clone https://github.com/YoshitakaMo/localcolabfold.git {install_path}\n",
        "\n",
        "    %cd {install_path}\n",
        "    !/root/.pixi/bin/pixi install\n",
        "\n",
        "    if os.path.exists(os.path.join(install_path, \".pixi\")):\n",
        "        print(\"â³ Paketleme iÅŸlemi baÅŸlÄ±yor...\")\n",
        "        %cd /content\n",
        "        !tar -cf colabfold_yedek.tar localcolabfold\n",
        "        os.makedirs(Work_on_dir, exist_ok=True)\n",
        "        !mv colabfold_yedek.tar \"{backup_path}\"\n",
        "        print(\"âœ… Ä°ÅLEM TAMAM: Pixi ile kurulum ve yedekleme baÅŸarÄ±lÄ±.\")\n",
        "    else:\n",
        "        raise SystemExit(\"âŒ HATA: Pixi ortamÄ± oluÅŸturulamadÄ±!\")\n",
        "else:\n",
        "    print(\"âœ… Sistem zaten yÃ¼klÃ¼.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgdttGmd1bZQ"
      },
      "source": [
        "##**PATH$**\n",
        "---\n",
        "Kurulan dosyalarÄ± sisteme tanÄ±tÄ±r ve AlphaFold2 motorunun Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± test eder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "5CETc_EM2K3p",
        "outputId": "0b4ea0fb-abca-44c0-acf1-8319e79ed022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”— PATH ayarlandÄ±: /content/localcolabfold/.pixi/envs/default/bin\n",
            "\n",
            "Sistem Test Ediliyor...\n",
            "usage: colabfold_batch [-h] [--msa-only]\n",
            "                       [--msa-mode {mmseqs2_uniref_env,mmseqs2_uniref_env_envpair,mmseqs2_uniref,single_sequence}]\n",
            "                       [--pair-mode {unpaired,paired,unpaired_paired}]\n",
            "                       [--pair-strategy {complete,greedy}] [--templates]\n",
            "                       [--custom-template-path CUSTOM_TEMPLATE_PATH]\n",
            "\n",
            "âœ… SÄ°STEM BÄ°LEÅENLERÄ° VE Colabfold HAZIR.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "bin_path = \"/content/localcolabfold/.pixi/envs/default/bin\"\n",
        "\n",
        "if os.path.exists(bin_path):\n",
        "    if bin_path not in os.environ['PATH']:\n",
        "        os.environ['PATH'] = f\"{bin_path}:{os.environ['PATH']}\"\n",
        "        print(f\"ğŸ”— PATH ayarlandÄ±: {bin_path}\\n\")\n",
        "\n",
        "    os.environ['MPLBACKEND'] = 'Agg'\n",
        "\n",
        "    print(\"Sistem Test Ediliyor...\")\n",
        "    !colabfold_batch --help | head -n 5\n",
        "\n",
        "    print(\"\\nâœ… SÄ°STEM BÄ°LEÅENLERÄ° VE Colabfold HAZIR.\")\n",
        "else:\n",
        "    print(\"âŒ KRÄ°TÄ°K HATA: Kurulum tamamlanmÄ±ÅŸ gÃ¶rÃ¼nmÃ¼yor.\")\n",
        "    raise SystemExit(\"PATH bulunamadÄ±ÄŸÄ± iÃ§in iÅŸlem durduruldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX41E4FP_t_6"
      },
      "source": [
        "## Colab Fold **RUN** â–¶ï¸\n",
        "Sistem BileÅŸenlerinin ve Fasta dosyalarÄ±nÄ±zÄ±n hazÄ±r olduÄŸundan eminseniz `RUN` baÅŸlatabilirsiniz.\n",
        "\n",
        "---\n",
        "##### â„¹ï¸ BÄ°LGÄ°LENDÄ°RME:\n",
        "* Colabfold, **`Folding/...fasta_parts`** klasÃ¶rÃ¼ iÃ§indeki oluÅŸturulan dosyalarÄ± Ã§alÄ±ÅŸtÄ±rabilir.\n",
        "\n",
        "* Ã‡Ä±ktÄ±lar `colabfold_results` klasÃ¶rÃ¼ne kaydedilecektir.\n",
        "\n",
        "* **Ã–nceden** elde edilmiÅŸ eski sonuÃ§lar **silinmektedir** ve yeniden temiz bir ÅŸekilde `colabfold_results` klasÃ¶rÃ¼ne  Ã§Ä±ktÄ±lar yÃ¼klenecektir.\n",
        "\n",
        "---\n",
        "#####âš ï¸UYARIâš ï¸:\n",
        "**TÃ¼m notebook hÃ¼crelerinin sÄ±rasÄ±yla yÃ¼rÃ¼tÃ¼ldÃ¼ÄŸÃ¼ senaryoda** sistem otomatik olarak sonuÃ§larÄ± bilgisayarÄ±nÄ±zÄ±n `Downloads` klasÃ¶rÃ¼ne indirecektir. DiÄŸer hÃ¼crelerin Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± Ã¶nemsemeden ham Ã§Ä±ktÄ±yÄ± almak istiyorsanÄ±z Drive dizininizdeki `Folding/colabfold_results` dosyasÄ±nÄ± (**hÃ¼creyi tekrar Ã§alÄ±ÅŸtÄ±rmadan**) kontrol ediniz.\n",
        "\n",
        "---\n",
        "\n",
        "####VarsayÄ±lan ayarlar\n",
        "- **`--templates`**:PDB veritabanÄ±ndaki benzer yapÄ±larÄ± \"iskelet\" olarak kullanÄ±r.\n",
        "- **`--pair-mode unpaired_paired`**: GeniÅŸ tarama modu.\n",
        "- **`--model-type alphafold2_multimer_v3`**: Dimer, trimer yapÄ±larÄ± keÅŸfeder\n",
        "- **`--num-recycle 3`**: DÃ¼ÅŸÃ¼k derecede optimizasyon dÃ¶ngÃ¼sÃ¼.\n",
        "\n",
        "- **`--amber`** and **`use_gpu_relax`**: YÃ¼ksek doÄŸrlulukta relaxed.pdb modellerini oluÅŸturur. (`/colabfold_results` 'u inceleyin). VarsayÄ±lan olarak `False` durumdadÄ±r. EtkinleÅŸtirilmesi yÃ¼ksek RAM gÃ¼cÃ¼ (VRAM) kullanmayÄ± gerektirir. VRAM ve GPU birimleri iÃ§in [Google Colab Ãœcretli hizmetler](https://colab.research.google.com/signup?utm_source=resource_tab&utm_medium=link&utm_campaign=payg_learn_more&authuser=1)'i ziyaret edebilirsiniz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WOseUlzl62lB",
        "outputId": "43263c11-0e8b-490c-f26e-a933b2e0df14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ Temizlik YapÄ±ldÄ±: '/content/drive/MyDrive/Folding/colabfold_results' ve iÃ§eriÄŸi silindi.\n",
            "âš ï¸ UYARI: Orijinal fasta dosyasÄ± bulunamadÄ±! (HPV.fasta)\n",
            "ğŸ“‚ Hedef: /content/drive/MyDrive/Folding/HPV_fasta_parts\n",
            "ğŸ“‚ Ã‡Ä±ktÄ±: /content/drive/MyDrive/Folding/colabfold_results\n",
            "------------------------------------------------------------\n",
            "\n",
            "ğŸ”‚ Ä°ÅLEM: [1/1] | DOSYA: [1/121] ('HPV_part1.fasta') BaÅŸlatÄ±lÄ±yor...\n",
            "\n",
            "\n",
            "2026-02-02 15:42:13,090 Running colabfold 1.5.5 (83ee93d262a99ad62d6f0897c5ddd37eb918d385)\n",
            "\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   0%|          | 0/3722752000 [00:00<?, ?it/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   0%|          | 16.0M/3.47G [00:00<00:22, 163MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   1%|          | 37.1M/3.47G [00:00<00:18, 197MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   2%|â–         | 59.6M/3.47G [00:00<00:17, 215MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   2%|â–         | 80.1M/3.47G [00:00<00:18, 195MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   3%|â–         | 98.9M/3.47G [00:00<00:19, 190MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   3%|â–         | 117M/3.47G [00:00<00:20, 179MB/s] \n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   4%|â–         | 141M/3.47G [00:00<00:17, 199MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   5%|â–         | 160M/3.47G [00:00<00:20, 174MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   5%|â–Œ         | 186M/3.47G [00:01<00:17, 199MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   6%|â–Œ         | 210M/3.47G [00:01<00:16, 213MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   6%|â–‹         | 231M/3.47G [00:01<00:16, 212MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   7%|â–‹         | 251M/3.47G [00:01<00:17, 203MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   8%|â–Š         | 271M/3.47G [00:01<00:17, 196MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   8%|â–Š         | 294M/3.47G [00:01<00:16, 208MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:   9%|â–‰         | 318M/3.47G [00:01<00:15, 221MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  10%|â–‰         | 339M/3.47G [00:01<00:15, 218MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  10%|â–ˆ         | 362M/3.47G [00:01<00:14, 224MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  11%|â–ˆ         | 384M/3.47G [00:01<00:15, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  11%|â–ˆâ–        | 408M/3.47G [00:02<00:14, 229MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  12%|â–ˆâ–        | 430M/3.47G [00:02<00:14, 222MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  13%|â–ˆâ–        | 451M/3.47G [00:02<00:15, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  13%|â–ˆâ–        | 472M/3.47G [00:02<00:15, 207MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  14%|â–ˆâ–        | 492M/3.47G [00:02<00:15, 207MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  14%|â–ˆâ–        | 512M/3.47G [00:02<00:17, 182MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  15%|â–ˆâ–Œ        | 534M/3.47G [00:02<00:16, 195MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  16%|â–ˆâ–Œ        | 556M/3.47G [00:02<00:15, 205MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  16%|â–ˆâ–Œ        | 576M/3.47G [00:02<00:16, 189MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  17%|â–ˆâ–‹        | 598M/3.47G [00:03<00:15, 201MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  18%|â–ˆâ–Š        | 623M/3.47G [00:03<00:14, 216MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  18%|â–ˆâ–Š        | 644M/3.47G [00:04<00:54, 55.7MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  19%|â–ˆâ–‰        | 669M/3.47G [00:04<00:40, 75.2MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  19%|â–ˆâ–‰        | 687M/3.47G [00:04<00:34, 86.5MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  20%|â–ˆâ–‰        | 706M/3.47G [00:04<00:28, 103MB/s] \n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  21%|â–ˆâ–ˆ        | 733M/3.47G [00:04<00:22, 132MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  21%|â–ˆâ–ˆ        | 753M/3.47G [00:04<00:23, 126MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  22%|â–ˆâ–ˆâ–       | 770M/3.47G [00:05<00:21, 137MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  22%|â–ˆâ–ˆâ–       | 794M/3.47G [00:05<00:18, 160MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  23%|â–ˆâ–ˆâ–       | 814M/3.47G [00:05<00:16, 173MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  24%|â–ˆâ–ˆâ–       | 836M/3.47G [00:05<00:15, 187MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  24%|â–ˆâ–ˆâ–       | 858M/3.47G [00:05<00:14, 199MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  25%|â–ˆâ–ˆâ–       | 879M/3.47G [00:05<00:14, 196MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  25%|â–ˆâ–ˆâ–Œ       | 902M/3.47G [00:05<00:13, 209MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  26%|â–ˆâ–ˆâ–Œ       | 925M/3.47G [00:05<00:12, 218MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  27%|â–ˆâ–ˆâ–‹       | 948M/3.47G [00:05<00:12, 224MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  27%|â–ˆâ–ˆâ–‹       | 970M/3.47G [00:05<00:11, 226MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  28%|â–ˆâ–ˆâ–Š       | 994M/3.47G [00:06<00:11, 232MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  29%|â–ˆâ–ˆâ–Š       | 0.99G/3.47G [00:06<00:11, 235MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  29%|â–ˆâ–ˆâ–‰       | 1.02G/3.47G [00:06<00:11, 231MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  30%|â–ˆâ–ˆâ–‰       | 1.04G/3.47G [00:06<00:11, 227MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  31%|â–ˆâ–ˆâ–ˆ       | 1.06G/3.47G [00:06<00:11, 230MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  31%|â–ˆâ–ˆâ–ˆ       | 1.08G/3.47G [00:06<00:11, 221MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.11G/3.47G [00:06<00:10, 237MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  33%|â–ˆâ–ˆâ–ˆâ–      | 1.13G/3.47G [00:06<00:11, 223MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  33%|â–ˆâ–ˆâ–ˆâ–      | 1.15G/3.47G [00:06<00:10, 227MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.17G/3.47G [00:07<00:11, 214MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.19G/3.47G [00:07<00:11, 212MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.21G/3.47G [00:07<00:10, 221MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.24G/3.47G [00:07<00:10, 226MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.26G/3.47G [00:07<00:10, 227MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.28G/3.47G [00:11<02:01, 19.4MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.30G/3.47G [00:11<01:34, 24.8MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.31G/3.47G [00:11<01:14, 31.2MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.33G/3.47G [00:11<00:59, 38.7MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.34G/3.47G [00:11<00:50, 45.6MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.36G/3.47G [00:11<00:37, 60.0MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.38G/3.47G [00:11<00:29, 77.4MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.39G/3.47G [00:12<00:25, 86.0MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.41G/3.47G [00:12<00:23, 94.1MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.42G/3.47G [00:12<00:21, 103MB/s] \n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.43G/3.47G [00:12<00:19, 110MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.45G/3.47G [00:12<00:17, 123MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.47G/3.47G [00:12<00:16, 133MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.48G/3.47G [00:12<00:15, 136MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.49G/3.47G [00:12<00:15, 141MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.51G/3.47G [00:12<00:14, 144MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.52G/3.47G [00:12<00:13, 151MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.54G/3.47G [00:13<00:13, 154MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.47G [00:13<00:12, 162MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.58G/3.47G [00:13<00:11, 181MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.59G/3.47G [00:13<00:11, 168MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.61G/3.47G [00:13<00:11, 179MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.64G/3.47G [00:13<00:09, 198MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.65G/3.47G [00:13<00:12, 159MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.68G/3.47G [00:13<00:10, 176MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.69G/3.47G [00:14<00:20, 92.6MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.71G/3.47G [00:14<00:16, 113MB/s] \n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.74G/3.47G [00:14<00:13, 135MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.76G/3.47G [00:14<00:11, 154MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.77G/3.47G [00:14<00:11, 164MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.80G/3.47G [00:14<00:09, 182MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.82G/3.47G [00:14<00:09, 192MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.84G/3.47G [00:15<00:08, 201MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.86G/3.47G [00:15<00:08, 198MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.88G/3.47G [00:15<00:08, 208MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.90G/3.47G [00:15<00:08, 193MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.92G/3.47G [00:15<00:09, 184MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.94G/3.47G [00:15<00:08, 194MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.96G/3.47G [00:15<00:07, 202MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.98G/3.47G [00:15<00:07, 212MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.01G/3.47G [00:15<00:07, 222MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.03G/3.47G [00:16<00:07, 211MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.05G/3.47G [00:16<00:07, 211MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.07G/3.47G [00:16<00:07, 213MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.09G/3.47G [00:16<00:07, 208MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.11G/3.47G [00:16<00:06, 209MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.13G/3.47G [00:16<00:06, 218MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.15G/3.47G [00:16<00:07, 192MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.17G/3.47G [00:16<00:06, 200MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.19G/3.47G [00:16<00:06, 211MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.21G/3.47G [00:16<00:06, 214MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.23G/3.47G [00:17<00:06, 213MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.25G/3.47G [00:17<00:06, 209MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.28G/3.47G [00:17<00:05, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.30G/3.47G [00:17<00:05, 227MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.32G/3.47G [00:17<00:05, 233MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.35G/3.47G [00:17<00:04, 241MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.37G/3.47G [00:17<00:04, 249MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.39G/3.47G [00:17<00:05, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.42G/3.47G [00:17<00:05, 215MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.44G/3.47G [00:18<00:05, 219MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.46G/3.47G [00:18<00:05, 215MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.48G/3.47G [00:18<00:04, 214MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.50G/3.47G [00:18<00:04, 220MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.52G/3.47G [00:18<00:04, 211MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.54G/3.47G [00:18<00:04, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.56G/3.47G [00:18<00:04, 225MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.59G/3.47G [00:18<00:04, 230MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.61G/3.47G [00:18<00:04, 229MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.63G/3.47G [00:18<00:03, 232MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.65G/3.47G [00:19<00:03, 235MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.68G/3.47G [00:19<00:03, 229MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.70G/3.47G [00:19<00:03, 220MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.72G/3.47G [00:19<00:03, 230MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.74G/3.47G [00:19<00:03, 233MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.77G/3.47G [00:19<00:03, 241MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.79G/3.47G [00:19<00:03, 238MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.81G/3.47G [00:19<00:02, 236MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.83G/3.47G [00:19<00:03, 197MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.86G/3.47G [00:20<00:03, 208MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.88G/3.47G [00:20<00:02, 217MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.90G/3.47G [00:20<00:02, 211MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.92G/3.47G [00:20<00:02, 227MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.95G/3.47G [00:20<00:02, 216MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.97G/3.47G [00:20<00:02, 223MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.99G/3.47G [00:20<00:02, 214MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.01G/3.47G [00:20<00:02, 218MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.03G/3.47G [00:20<00:02, 226MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.06G/3.47G [00:21<00:01, 225MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.08G/3.47G [00:23<00:14, 29.3MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.09G/3.47G [00:23<00:10, 37.9MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.11G/3.47G [00:23<00:07, 48.4MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.13G/3.47G [00:23<00:06, 58.8MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.15G/3.47G [00:23<00:04, 75.1MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.17G/3.47G [00:23<00:03, 87.4MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.18G/3.47G [00:24<00:02, 105MB/s] \n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.20G/3.47G [00:24<00:02, 110MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.22G/3.47G [00:24<00:02, 116MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.23G/3.47G [00:24<00:01, 127MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.25G/3.47G [00:24<00:01, 139MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.27G/3.47G [00:24<00:01, 159MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.29G/3.47G [00:24<00:01, 174MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.31G/3.47G [00:24<00:00, 175MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.32G/3.47G [00:24<00:00, 177MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.34G/3.47G [00:25<00:00, 144MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.36G/3.47G [00:25<00:00, 145MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.37G/3.47G [00:25<00:00, 151MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.39G/3.47G [00:25<00:00, 163MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.41G/3.47G [00:25<00:00, 167MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.42G/3.47G [00:25<00:00, 170MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.44G/3.47G [00:25<00:00, 173MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.46G/3.47G [00:25<00:00, 140MB/s]\n",
            "Downloading alphafold2_ptm weights to /root/.cache/colabfold: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.47G/3.47G [00:25<00:00, 143MB/s]\n",
            "2026-02-02 15:42:42.358614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770046962.651898    1672 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770046962.729533    1672 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770046963.326079    1672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770046963.326128    1672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770046963.326132    1672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770046963.326135    1672 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-02 15:42:53,722 Running on GPU\n",
            "2026-02-02 15:42:55,770 Found 8 citations for tools or databases\n",
            "2026-02-02 15:42:55,773 Query 1/1: ALK24573.1 (length 306)\n",
            "\n",
            "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\n",
            "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\n",
            "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\n",
            "COMPLETE: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [elapsed: 00:00 remaining: 00:00]\n",
            "COMPLETE: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [elapsed: 00:01 remaining: 00:00]\n",
            "2026-02-02 15:43:02,131 Sequence 0 found templates: ['7tuk_A', '7tuk_B', '7tul_B', '7tul_A', '1wz4_A', '7tuk_A', '7tuk_B', '7tul_B']\n",
            "2026-02-02 15:43:02,921 Setting max_seq=512, max_extra_seq=593\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770046996.472902    1672 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2026-02-02 15:43:17.406143: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30467808 exceeds 10% of free system memory.\n",
            "2026-02-02 15:43:17.594632: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30467808 exceeds 10% of free system memory.\n",
            "2026-02-02 15:43:17.617644: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 60935616 exceeds 10% of free system memory.\n",
            "2026-02-02 15:44:28,793 alphafold2_ptm_model_1_seed_000 recycle=0 pLDDT=46.3 pTM=0.3\n",
            "2026-02-02 15:45:34,050 alphafold2_ptm_model_1_seed_000 recycle=1 pLDDT=44.4 pTM=0.294 tol=5.57\n",
            "2026-02-02 15:45:34,051 alphafold2_ptm_model_1_seed_000 took 136.4s (1 recycles)\n",
            "2026-02-02 15:45:57,517 alphafold2_ptm_model_2_seed_000 recycle=0 pLDDT=49 pTM=0.276\n",
            "2026-02-02 15:46:20,881 alphafold2_ptm_model_2_seed_000 recycle=1 pLDDT=46.9 pTM=0.261 tol=6.91\n",
            "2026-02-02 15:46:20,882 alphafold2_ptm_model_2_seed_000 took 46.6s (1 recycles)\n",
            "2026-02-02 15:47:13,737 alphafold2_ptm_model_3_seed_000 recycle=0 pLDDT=49.5 pTM=0.26\n",
            "2026-02-02 15:48:05,138 alphafold2_ptm_model_3_seed_000 recycle=1 pLDDT=47.6 pTM=0.242 tol=8.2\n",
            "2026-02-02 15:48:05,140 alphafold2_ptm_model_3_seed_000 took 104.1s (1 recycles)\n",
            "2026-02-02 15:48:28,273 alphafold2_ptm_model_4_seed_000 recycle=0 pLDDT=45.7 pTM=0.249\n",
            "2026-02-02 15:48:51,336 alphafold2_ptm_model_4_seed_000 recycle=1 pLDDT=45.1 pTM=0.234 tol=6\n",
            "2026-02-02 15:48:51,337 alphafold2_ptm_model_4_seed_000 took 46.0s (1 recycles)\n",
            "2026-02-02 15:49:14,936 alphafold2_ptm_model_5_seed_000 recycle=0 pLDDT=47.6 pTM=0.27\n",
            "2026-02-02 15:49:38,276 alphafold2_ptm_model_5_seed_000 recycle=1 pLDDT=46.3 pTM=0.249 tol=5.65\n",
            "2026-02-02 15:49:38,277 alphafold2_ptm_model_5_seed_000 took 46.8s (1 recycles)\n",
            "2026-02-02 15:49:38,396 reranking models by 'plddt' metric\n",
            "2026-02-02 15:49:38,397 rank_001_alphafold2_ptm_model_3_seed_000 pLDDT=47.6 pTM=0.242\n",
            "2026-02-02 15:49:38,402 rank_002_alphafold2_ptm_model_2_seed_000 pLDDT=46.9 pTM=0.261\n",
            "2026-02-02 15:49:38,406 rank_003_alphafold2_ptm_model_5_seed_000 pLDDT=46.3 pTM=0.249\n",
            "2026-02-02 15:49:38,411 rank_004_alphafold2_ptm_model_4_seed_000 pLDDT=45.1 pTM=0.234\n",
            "2026-02-02 15:49:38,415 rank_005_alphafold2_ptm_model_1_seed_000 pLDDT=44.4 pTM=0.294\n",
            "2026-02-02 15:49:40,345 Done\n",
            "âœ… TamamlandÄ±: HPV_part1.fasta\n",
            "\n",
            "âœ…HEDEFLENEN (1) ADET Ä°ÅLEM BÄ°TTÄ°! SonuÃ§lar: '/content/drive/MyDrive/Folding/colabfold_results'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import glob\n",
        "import sys\n",
        "import subprocess\n",
        "import signal\n",
        "\n",
        "use_amber = False  #True VRAM etkinleÅŸtirildiÄŸinden emin iseniz 'True' yapÄ±labilir.\n",
        "use_gpu_relax = False  #True\n",
        "\n",
        "try:\n",
        "    Work_on_dir\n",
        "except NameError:\n",
        "    Work_on_dir = \"/content/drive/MyDrive/Folding\"\n",
        "\n",
        "clean_target_dir = os.path.join(Work_on_dir, \"colabfold_results\")\n",
        "if os.path.exists(clean_target_dir):\n",
        "    try:\n",
        "        shutil.rmtree(clean_target_dir)\n",
        "        print(f\"ğŸ§¹ Temizlik YapÄ±ldÄ±: '{clean_target_dir}' ve iÃ§eriÄŸi silindi.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Temizlik sÄ±rasÄ±nda hata: {e}\")\n",
        "\n",
        "if 'run_mode' in locals() and run_mode == \"multimerv3\":\n",
        "    model_type_cli = \"alphafold2_multimer_v3\"\n",
        "else:\n",
        "    model_type_cli = \"alphafold2_ptm\"\n",
        "\n",
        "try:\n",
        "    CALISMA_YOLU = Work_on_dir\n",
        "    base_name_auto = os.path.splitext(raw_data)[0]\n",
        "    parts_dir = os.path.join(CALISMA_YOLU, f\"{base_name_auto}_fasta_parts\")\n",
        "    output_dir = os.path.join(CALISMA_YOLU, \"colabfold_results\")\n",
        "\n",
        "    found_files = glob.glob(os.path.join(parts_dir, f\"{base_name_auto}_part*.fasta\"))\n",
        "    total_parts = len(found_files)\n",
        "\n",
        "    if total_parts == 0:\n",
        "        raise FileNotFoundError(f\"KlasÃ¶rde hiÃ§ fasta parÃ§asÄ± bulunamadÄ±: {parts_dir}\")\n",
        "\n",
        "    start_at = 1\n",
        "    should_clean = True\n",
        "\n",
        "    batch_quota = kota if 'kota' in locals() else total_parts\n",
        "\n",
        "    if 'take_up' in locals() and take_up and 'resume_as' in locals():\n",
        "        should_clean = False\n",
        "        start_at = resume_as\n",
        "        if start_at > total_parts:\n",
        "            print(f\"\\nâ›” HATA: Ä°stediÄŸiniz baÅŸlangÄ±Ã§ ({start_at}), toplam parÃ§adan ({total_parts}) bÃ¼yÃ¼k!\")\n",
        "\n",
        "    end_at = start_at + batch_quota - 1\n",
        "    if end_at > total_parts:\n",
        "        end_at = total_parts\n",
        "\n",
        "    if should_clean:\n",
        "        if os.path.exists(output_dir):\n",
        "            try:\n",
        "                shutil.rmtree(output_dir)\n",
        "                print(\"ğŸ§¹ Temizlik: Eski sonuÃ§lar silindi.\")\n",
        "            except: pass\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "    else:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    original_fasta_path = os.path.join(CALISMA_YOLU, raw_data)\n",
        "    backup_fasta_path = os.path.join(output_dir, raw_data)\n",
        "\n",
        "    if os.path.exists(original_fasta_path):\n",
        "        shutil.copy2(original_fasta_path, backup_fasta_path)\n",
        "    else:\n",
        "        print(f\"âš ï¸ UYARI: Orijinal fasta dosyasÄ± bulunamadÄ±! ({raw_data})\")\n",
        "\n",
        "    print(f\"ğŸ“‚ Hedef: {parts_dir}\")\n",
        "    print(f\"ğŸ“‚ Ã‡Ä±ktÄ±: {output_dir}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    recycle_count = cycle if 'cycle' in locals() else 3\n",
        "    process_counter = 0\n",
        "\n",
        "    for i in range(start_at, end_at + 1):\n",
        "        process_counter += 1\n",
        "        part_filename = f\"{base_name_auto}_part{i}.fasta\"\n",
        "\n",
        "        input_file_path = f\"{parts_dir}/{part_filename}\"\n",
        "        log_path = f\"{output_dir}/{base_name_auto}_part{i}_log.txt\"\n",
        "\n",
        "        if os.path.exists(input_file_path):\n",
        "            print(f\"\\nğŸ”‚ Ä°ÅLEM: [{process_counter}/{batch_quota}] | DOSYA: [{i}/{total_parts}] ('{part_filename}') BaÅŸlatÄ±lÄ±yor...\\n\\n\")\n",
        "\n",
        "            current_config = {\n",
        "                \"raw_data\": raw_data,\n",
        "                \"model_type\": model_type_cli,\n",
        "                \"split_param\": split_param if 'split_param' in locals() else \"None\",\n",
        "                \"cycle\": recycle_count,\n",
        "                \"total_parts\": total_parts,\n",
        "                \"processed_part\": i,\n",
        "                \"kota\": kota if 'kota' in locals() else \"Hepsi\",\n",
        "                \"take_up\": take_up if 'take_up' in locals() else False,\n",
        "                \"resume_as\": resume_as if 'resume_as' in locals() else 1\n",
        "            }\n",
        "\n",
        "            with open(log_path, \"w\") as logfile:\n",
        "                json.dump(current_config, logfile)\n",
        "                logfile.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "                logfile.flush()\n",
        "\n",
        "                command = [\n",
        "                    \"colabfold_batch\",\n",
        "                    input_file_path,\n",
        "                    output_dir,\n",
        "                    \"--templates\"\n",
        "                ]\n",
        "\n",
        "                if use_amber:\n",
        "                    command.append(\"--amber\")\n",
        "                if use_gpu_relax:\n",
        "                    command.append(\"--use-gpu-relax\")\n",
        "\n",
        "                command.extend([\n",
        "                    \"--num-recycle\", str(recycle_count),\n",
        "                    \"--pair-mode\", \"unpaired_paired\",\n",
        "                    \"--model-type\", model_type_cli\n",
        "                ])\n",
        "\n",
        "                env = os.environ.copy()\n",
        "                env[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "\n",
        "                process = subprocess.Popen(\n",
        "                    command,\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.STDOUT,\n",
        "                    text=True,\n",
        "                    bufsize=1,\n",
        "                    env=env\n",
        "                )\n",
        "\n",
        "                try:\n",
        "                    for line in iter(process.stdout.readline, ''):\n",
        "                        print(line, end='')\n",
        "                        logfile.write(line)\n",
        "                        logfile.flush()\n",
        "\n",
        "                    process.wait()\n",
        "\n",
        "                    if process.returncode == 0:\n",
        "                        print(f\"âœ… TamamlandÄ±: {part_filename}\")\n",
        "                    else:\n",
        "                        print(f\"âš ï¸ Hata ile bitti: {part_filename} (Kod: {process.returncode})\")\n",
        "\n",
        "                except KeyboardInterrupt:\n",
        "                    print(f\"\\nâ›” Ä°ÅLEM KULLANICI TARAFINDAN KESÄ°LDÄ°! ({part_filename})\\n\")\n",
        "                    print(\"ğŸ›‘ Arka plan iÅŸlemleri fiziksel olarak durduruldu....\")\n",
        "                    process.kill()\n",
        "                    process.wait()\n",
        "                    sys.exit(1)\n",
        "\n",
        "        else:\n",
        "            print(f\"âš ï¸ Dosya bulunamadÄ±: {part_filename}\")\n",
        "\n",
        "    print(f\"\\nâœ…HEDEFLENEN ({process_counter}) ADET Ä°ÅLEM BÄ°TTÄ°! SonuÃ§lar: '{output_dir}'\")\n",
        "\n",
        "except SystemExit:\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"âŒ BEKLENMEYEN HATA: {e}\")\n",
        "    raise SystemExit(\"Hata nedeniyle sonraki hÃ¼crelere geÃ§iÅŸ durduruldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuU3Ls2TFIcA"
      },
      "source": [
        "### **KÃ–K DOSYASI TASNÄ°FÄ°** - (optional)\n",
        "\n",
        "**KÃ¶k dizini `colabfold_results` iÃ§inde karmaÅŸÄ±k dosyalarÄ± derleyip dÃ¼zenli bir tasnif yapÄ±lmasÄ±nÄ± saÄŸlar.**\n",
        "\n",
        "---\n",
        "### âš ï¸ UYARI :  **`RUN`** iÅŸlemi tamamlanmadan Ã§alÄ±ÅŸtÄ±rmayÄ±nÄ±z.\n",
        "\n",
        "---\n",
        "####Not:\n",
        "- Uzun sÃ¼ren `RUN` iÅŸleminden sonra oturumunuz sonlanabilir. Bu durumda **`Drive`** kÃ¶k dizine baÄŸlantÄ± kurabilir Ã¶nceki bÃ¶lÃ¼mleri tekrardan Ã§alÄ±ÅŸtÄ±rmaya gerek kalmadan kÃ¶k dizinde iÅŸlem yapÄ±labilirsiniz.\n",
        "\n",
        "- KÃ¶k dizinizin oluÅŸtuÄŸu ve **RUN** iÅŸleminin  bittiÄŸinden eminseniz aÅŸaÄŸÄ±daki  `activing_code` kutucuÄŸunu iÅŸaretleyerek devam edin.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yHzQM0gkIzDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0012bcd-f8fe-4fbc-9607-b8e8267a87c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Ä°ÅLEM TAMAMLANDI: 9 dosya dÃ¼zenlendi.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "from google.colab import drive\n",
        "\n",
        "activing_code = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if not activing_code:\n",
        "    print(\"Ã‡alÄ±ÅŸtÄ±rmak iÃ§in kutucuÄŸu iÅŸaretleyin.\\n\")\n",
        "    sys.exit()\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"ğŸ”Œ Google Drive baÄŸlanÄ±yor...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Folding/colabfold_results\"\n",
        "\n",
        "if not os.path.exists(base_path):\n",
        "    print(f\"âŒ HATA: '{base_path}' yolu bulunamadÄ±.\")\n",
        "    sys.exit()\n",
        "\n",
        "for item in os.listdir(base_path):\n",
        "    item_path = os.path.join(base_path, item)\n",
        "\n",
        "    if os.path.isdir(item_path):\n",
        "        sub_files = os.listdir(item_path)\n",
        "        if \"part\" in item or \"_env\" in item or \"_pairgreedy\" in item:\n",
        "             for sub_file in sub_files:\n",
        "                src = os.path.join(item_path, sub_file)\n",
        "                dst = os.path.join(base_path, sub_file)\n",
        "                try:\n",
        "                    shutil.move(src, dst)\n",
        "                except: pass\n",
        "             try:\n",
        "                 shutil.rmtree(item_path)\n",
        "             except: pass\n",
        "\n",
        "\n",
        "files = [f for f in os.listdir(base_path) if os.path.isfile(os.path.join(base_path, f))]\n",
        "moved_count = 0\n",
        "pattern = re.compile(r\"^(YP_\\d+\\.\\d+|[A-Z0-9]+\\.\\d+|[A-Z0-9]+)\")\n",
        "\n",
        "for filename in files:\n",
        "    if filename.endswith(\".txt\") or filename.endswith(\".fasta\") or filename.endswith(\".json\") or filename == \"cite.bibtex\" or filename.startswith(\".\"):\n",
        "        continue\n",
        "\n",
        "    match = pattern.match(filename)\n",
        "    if match:\n",
        "        file_id = match.group(0)\n",
        "        clean_id = file_id\n",
        "\n",
        "        if clean_id == filename or len(clean_id) < 3:\n",
        "            continue\n",
        "\n",
        "        target_folder = os.path.join(base_path, clean_id)\n",
        "        source_path = os.path.join(base_path, filename)\n",
        "        dest_path = os.path.join(target_folder, filename)\n",
        "\n",
        "        try:\n",
        "            os.makedirs(target_folder, exist_ok=True)\n",
        "            shutil.move(source_path, dest_path)\n",
        "            moved_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ TaÅŸÄ±ma hatasÄ±: {filename} -> {e}\")\n",
        "\n",
        "for item in os.listdir(base_path):\n",
        "    item_path = os.path.join(base_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        if item.endswith(\"_env\") or item.endswith(\"_pairgreedy\"):\n",
        "            try: shutil.rmtree(item_path)\n",
        "            except: pass\n",
        "        elif not os.listdir(item_path):\n",
        "            try: os.rmdir(item_path)\n",
        "            except: pass\n",
        "\n",
        "remaining_files = [f for f in os.listdir(base_path) if os.path.isfile(os.path.join(base_path, f))]\n",
        "deleted_files = 0\n",
        "\n",
        "for filename in remaining_files:\n",
        "    if (filename.endswith(\".txt\") or\n",
        "        filename.endswith(\".fasta\") or\n",
        "        filename.endswith(\"config.json\") or\n",
        "        filename == \"cite.bibtex\" or\n",
        "        filename.startswith(\".\")):\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(base_path, filename)\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "        deleted_files += 1\n",
        "    except: pass\n",
        "\n",
        "print(f\"\\nâœ… Ä°ÅLEM TAMAMLANDI: {moved_count} dosya dÃ¼zenlendi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8HLp8oxBZxd"
      },
      "source": [
        "##### Tasnif iÅŸleminin doÄŸruluÄŸunu kontrolÃ¼ iÃ§in opsiyonel Ã§alÄ±ÅŸÄ±r."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c_Lke-hZ12Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b558290-6e34-4e1e-af1b-4c650e98a3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Folding/colabfold_results\n",
            "ALK24573.1\t     cite.bibtex  HPV_part1_log.txt  templates_101\n",
            "ALK24573.1.done.txt  config.json  log.txt\n"
          ]
        }
      ],
      "source": [
        "%cd  \"/content/drive/MyDrive/Folding/colabfold_results\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THAxH5JDgjIa"
      },
      "source": [
        "## SONUÃ‡LARI KAYDETME\n",
        "**TÃ¼m sonuÃ§larÄ± tek bir paket haline getirir ve bilgisayarÄ±nÄ±za indirir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wE8uvW3Mgriy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "04b5e511-49b7-4a19-c6b8-9860fb40960b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ 'HPV_part6_sp1.zip' hazÄ±rlanÄ±yor...\n",
            "\n",
            "â¬‡ï¸ Ä°ndirme baÅŸlatÄ±lÄ±yor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f7fef82f-dc5e-436c-8598-18a6e90e0c37\", \"HPV_part6_sp1.zip\", 1427809)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Ä°ÅLEM TAMAM: 'HPV_part6_sp1.zip' indirildi.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "results_dir = \"/content/drive/MyDrive/Folding/colabfold_results\"\n",
        "\n",
        "if os.path.exists(results_dir):\n",
        "    for item in os.listdir(results_dir):\n",
        "        item_path = f\"{results_dir}/{item}\"\n",
        "        if os.path.isdir(item_path) and not os.listdir(item_path):\n",
        "            try:\n",
        "                os.rmdir(item_path)\n",
        "            except: pass\n",
        "\n",
        "if 'raw_data' not in locals():\n",
        "    print(\"âš ï¸ DeÄŸiÅŸkenler hafÄ±zada yok. Log dosyasÄ±ndan okunuyor...\")\n",
        "    log_files = glob.glob(f\"{results_dir}/*_part*_log.txt\")\n",
        "\n",
        "    if log_files:\n",
        "        latest_log = max(log_files, key=os.path.getmtime)\n",
        "        try:\n",
        "            with open(latest_log, 'r') as f:\n",
        "                first_line = f.readline().strip()\n",
        "                if first_line.startswith(\"{\") and first_line.endswith(\"}\"):\n",
        "                    config = json.load(f)\n",
        "\n",
        "                    raw_data = config.get(\"raw_data\", \"unknown\")\n",
        "                    split_param = config.get(\"split_param\", \"None\")\n",
        "                    resume_as = config.get(\"resume_as\", 1)\n",
        "                    kota = config.get(\"kota\", 1)\n",
        "                    take_up = config.get(\"take_up\", False)\n",
        "\n",
        "                    print(f\"âœ… Config okundu: {raw_data}\")\n",
        "                else:\n",
        "                    raise ValueError(\"Log formatÄ± uymuyor.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Config hatasÄ±: {e}\")\n",
        "            raw_data = \"result\"; split_param = \"None\"; resume_as = 1; kota = 1; take_up = False\n",
        "    else:\n",
        "        print(\"âŒ Log bulunamadÄ±.\")\n",
        "        raw_data = \"result\"; split_param = \"None\"; resume_as = 1; kota = 1; take_up = False\n",
        "\n",
        "try:\n",
        "    clean_name = os.path.splitext(raw_data)[0]\n",
        "\n",
        "    if take_up:\n",
        "        end_val = int(resume_as) + int(kota) - 1\n",
        "        zip_name = f\"{clean_name}_part{resume_as}_to{end_val}_sp{split_param}\"\n",
        "\n",
        "    else:\n",
        "        zip_name = f\"{clean_name}_part{resume_as}_sp{split_param}\"\n",
        "\n",
        "except NameError:\n",
        "    zip_name = \"colabfold_results_backup\"\n",
        "\n",
        "output_zip_path = f\"/content/{zip_name}\"\n",
        "\n",
        "if os.path.exists(results_dir):\n",
        "    print(f\"\\nğŸ“¦ '{zip_name}.zip' hazÄ±rlanÄ±yor...\")\n",
        "\n",
        "    shutil.make_archive(output_zip_path, 'zip', results_dir)\n",
        "\n",
        "    print(\"\\nâ¬‡ï¸ Ä°ndirme baÅŸlatÄ±lÄ±yor...\")\n",
        "    files.download(f\"{output_zip_path}.zip\")\n",
        "\n",
        "    print(f\"\\nâœ… Ä°ÅLEM TAMAM: '{zip_name}.zip' indirildi.\")\n",
        "else:\n",
        "    print(f\"âŒ HATA: SonuÃ§ klasÃ¶rÃ¼ yok: {results_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rgdttGmd1bZQ"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1djQJPqLSpxpFeBztgKI2I7uM2l7jj71z",
      "authorship_tag": "ABX9TyMqwzYqVu4irtbE6wSr6K0k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}